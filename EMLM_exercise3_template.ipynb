{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TKO_7092 Evaluation of Machine Learning Methods 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Complete the tasks given to you in the letter below. In your submission, explain clearly, precisely, and comprehensively why the cross-validation described in the letter failed, what is the correct way to perform cross-validation in the given scenario, and why the correct cross-validation method will give a reliable estimate of the generalisation performance. Then implement the correct cross-validation for the scenario and report its results.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dear Data Scientist,\n",
    "\n",
    "I have a long-term research project regarding a specific set of proteins. I am attempting to discover small organic compounds that can bind strongly to these proteins and thus act as drugs. I have already made laboratory experiments to measure the affinities between some proteins and drug molecules.\n",
    "\n",
    "My colleague is working on another set of proteins, and the objectives of his project are similar to mine. He has recently discovered thousands of new potential drug molecules. He asked me if I could find the pairs that have the strongest affinities among his proteins and drug molecules. Obviously I do not have the resources to measure all the possible pairs in my laboratory, so I need to prioritise. I decided to do this with the help of machine learning, but I have encountered a problem.\n",
    "\n",
    "Here is what I have done so far: First I trained a K-nearest neighbours regressor with the parameter value K=10 using all the 400 measurements I had already made in the laboratory with my proteins and drug molecules. They comprise of 77 target proteins and 59 drug molecules. Then I performed a leave-one-out cross-validation with this same data to estimate the generalisation performance of the model. I used C-index and got a stellar score above 90%. Finally I used the model to predict the affinities of my colleague's proteins and drug molecules. The problem is: when I selected the highest predicted affinities and tried to verify them in the lab, I found that many of them are much lower in reality. My model clearly does not work despite the high cross-validation score.\n",
    "\n",
    "Please explain why my estimation failed and how leave-one-out cross-validation should be performed to get a reliable estimate. Also, implement the correct leave-one-out cross-validation and report its results. I need to know whether it would be a waste of my resources if I were to use my model any further.\n",
    "\n",
    "The data I used to create my model is available in the files `input.data`, `output.data` and `pairs.data` for you to use. The first file contains the features of the pairs, whereas the second contains their affinities. The third file contains the identifiers of the drug and target molecules of which the pairs are composed. The files are paired, i.e. the i<sup>*th*</sup> row in each file is about the same pair.\n",
    "\n",
    "Looking forward to hearing from you soon.\n",
    "\n",
    "Yours sincerely, \\\n",
    "Bio Scientist\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer the questions about cross-validation on pair-input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why did the estimation described in the letter fail?\n",
    "\n",
    "It allowed the model to “peek” at proteins and drugs that appear in both training and test sets. This led to data leakage and an overestimation of the model’s performance.\n",
    "\n",
    "The original approach used standard leave‐one‐out cross‐validation (LOOCV) where one pair (i.e. one specific protein–drug combination) was held out as a test sample while the model was trained on the remaining 399 pairs. This procedure failed for two important reasons:\n",
    "\n",
    "Data Leakage:\n",
    "\n",
    "In the dataset, each sample (row) represents a pair formed by one protein and one drug. Because many proteins and drugs appear in multiple pairs, even if you leave one pair out, its constituent protein or drug molecules are almost certainly present in other training examples. This means that when the model is tested on a held‐out pair, it has already “seen” its protein or drug in other contexts. As a consequence, the test sample is not independent from the training data. Thats why the performance metric gives an overly optimistic view of how well the model generalizes.\n",
    "\n",
    "Mismatch:\n",
    "\n",
    "In practical, the aim was to predict affinities for pairs involving entirely new proteins and drugs (from the colleague's dataset) that were never measured before. Standard LOOCV on pairs does not simulate this kind of situation because it does not ensure that the test pairs are composed of molecules that were not in the training set. Thus, while LOOCV on pairs can show excellent performance, it does not reflect the challenge of predicting on unseen molecules and that's why may lead to a model that performs poorly in real-world use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How should leave-one-out cross-validation be performed in the given scenario and why?\n",
    "\n",
    "When working with pair‐input data, each fold of cross‐validation must replicate the dependency structure that we will face when applying the model in practice. The key is to exclude from the training set those in‐sample observations that share a pair member with the test observation if that sharing does not occur in the real prediction scenario.\n",
    "\n",
    "In the lecture example there was provided four types of out‐of‐sample pair-input observations:\n",
    "\n",
    "Type A:\n",
    "The out‐of‐sample observation shares both pair members with the sample. (Standard LOOCV is acceptable here because the dependencies (both members seen in training) are the same as when using LOOCV.)\n",
    "\n",
    "Type B:\n",
    "The out‐of‐sample observation has a novel first pair member but shares the second pair member with the sample. (For proper evaluation, the training set must exclude observations that share the novel (first) pair member with the test observation)\n",
    "\n",
    "Type C:\n",
    "The test observation has a novel second pair member but shares the first pair member. (Thus, exclude training observations that share the novel (second) pair member)\n",
    "\n",
    "Type D:\n",
    "The test observation shares neither pair member with the sample (completely unseen). (To mimic this scenario, we must remove all training observations that share either pair member with the test observation)\n",
    "\n",
    "Because the colleague’s proteins and  drugs are entirely new, we are effectively interested in one of the scenarios where at least one, if not both, pair members are unseen. If we expect both components to be new (Type D), then the evaluation should exclude any training observation that shares either the protein or the drug with the test pair. \n",
    "\n",
    "Why this way?\n",
    "\n",
    "By excluding all training pairs that share either component with the test pair, we simulate the real‐world situation where neither the protein nor the drug has been seen before. This eliminates any dependency that might artificially inflate the performance estimate. With the dependent observations removed, the evaluation reflects the true generalization ability of the model on entirely new pairs. \n",
    "\n",
    "Each fold should leave out all pairs that contain a specific protein. This ensures that when predicting for a new protein, the model has never seen it before, leading to a realistic generalization estimate. This is crucial because in the actual application, the model will be making predictions on new proteins and new drug molecules, not just new pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries you need.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from scipy.stats import somersd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the utility functions you need in your analysis.\n",
    "\n",
    "def cindex(true, pred):\n",
    "    s_d = somersd(true, y=pred, alternative='two-sided')\n",
    "    c_index = (s_d.statistic + 1.0) / 2.0\n",
    "    return c_index\n",
    "\n",
    "def leave_one_group_out_cv(input_features, output_affinities, pairs, group_index, n_neighbors=10):\n",
    "    \"\"\"\n",
    "    Performs leave-one-group-out cross-validation.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_features: numpy array of shape (n_samples, n_features)\n",
    "    - output_affinities: numpy array of shape (n_samples,)\n",
    "    - pairs: numpy array of shape (n_samples, 2), where each row is [drug_id, protein_id]\n",
    "    - group_index: int, 0 for leave-one-drug-out, 1 for leave-one-protein-out\n",
    "    - n_neighbors: int, number of neighbors for KNN\n",
    "    \n",
    "    Returns:\n",
    "    - c_index: float, concordance index for the CV\n",
    "    \"\"\"\n",
    "    unique_groups = np.unique(pairs[:, group_index])\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "\n",
    "    for group in unique_groups:\n",
    "        test_mask = (pairs[:, group_index] == group)\n",
    "        train_mask = ~test_mask\n",
    "\n",
    "        if np.sum(test_mask) == 0:\n",
    "            continue  # Skip if no test samples (shouldn't happen)\n",
    "\n",
    "        X_train = input_features[train_mask]\n",
    "        y_train = output_affinities[train_mask]\n",
    "        X_test = input_features[test_mask]\n",
    "        y_test = output_affinities[test_mask]\n",
    "\n",
    "        # Train model\n",
    "        model = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "        model.fit(X_train, y_train)\n",
    "        pred = model.predict(X_test)\n",
    "\n",
    "        all_true.append(y_test)\n",
    "        all_pred.append(pred)\n",
    "\n",
    "    all_true = np.concatenate(all_true)\n",
    "    all_pred = np.concatenate(all_pred)\n",
    "    return cindex(all_true, all_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows in input.data:\n",
      "[[0.759222  0.709585  0.253151  0.421082  0.72778   0.404487  0.709027\n",
      "  0.242963  0.407292  0.379971  0.412465  0.284844  0.425915  0.747606\n",
      "  0.222227  0.445811  0.667796  0.684103  0.787706  0.336596  0.824543\n",
      "  0.672308  0.310471  0.56949   0.797567  0.313177  0.311688  0.452033\n",
      "  0.624945  0.581985  0.676889  0.813303  0.813624  0.113869  0.191247\n",
      "  0.457698  0.197378  0.278575  0.72427   0.626547  0.292438  0.484609\n",
      "  0.605063  0.868699  0.916641  0.938985  0.264985  0.463426  0.754346\n",
      "  0.128309  0.473564  0.450811  0.0700555 0.851803  0.70897   0.210471\n",
      "  0.225433  0.838616  0.16505   0.515334  0.332678  0.577533  0.678125\n",
      "  0.463608  0.538938  0.460883  0.345251 ]\n",
      " [0.0345836 0.30472   0.688257  0.296396  0.151878  0.830755  0.270656\n",
      "  0.705392  0.18612   0.0855935 0.285097  0.43646   0.372679  0.342203\n",
      "  0.619907  0.402184  0.802182  0.252357  0.102975  0.361315  0.832553\n",
      "  0.377971  0.520338  0.952467  0.950084  0.274851  0.510368  0.241743\n",
      "  0.472949  0.98426   0.4628    0.920805  0.229338  0.706394  0.945254\n",
      "  0.0692465 0.408385  0.954266  0.502783  0.534844  0.487878  0.432714\n",
      "  0.676921  0.509694  0.0791219 0.889453  0.588741  0.900397  0.157845\n",
      "  0.519728  0.419732  0.185939  0.277397  0.981273  0.831517  0.198395\n",
      "  0.783724  0.472762  0.730013  0.639373  0.445218  0.45568   0.0907368\n",
      "  0.308432  0.0790233 0.603089  0.197008 ]\n",
      " [0.737867  0.236079  0.905987  0.163612  0.801455  0.789823  0.393999\n",
      "  0.522067  0.411352  0.781861  0.303538  0.217715  0.358014  0.710752\n",
      "  0.80299   0.277269  0.832287  0.497475  0.174691  0.68881   0.732417\n",
      "  0.648917  0.444371  0.646489  0.15      0.175432  0.650843  0.298738\n",
      "  0.792569  0.159939  0.816026  0.681459  0.785289  0.478808  0.557274\n",
      "  0.697998  0.928214  0.831142  0.134644  0.663699  0.493744  0.80523\n",
      "  0.614058  0.815342  0.782061  0.631275  0.184718  0.711207  0.502769\n",
      "  0.587998  0.690468  0.487528  0.579977  0.150724  0.120252  0.450363\n",
      "  0.232817  0.595468  0.582292  0.836193  0.281514  0.79179   0.0816952\n",
      "  0.58345   0.422539  0.0764367 0.299662 ]\n",
      " [0.406913  0.60774   0.235365  0.888679  0.150347  0.598991  0.130108\n",
      "  0.465818  0.799953  0.906878  0.654509  0.662954  0.700847  0.667325\n",
      "  0.699708  0.757919  0.835217  0.639181  0.133472  0.724555  0.431937\n",
      "  0.221379  0.744795  0.165751  0.322982  0.519271  0.473923  0.765148\n",
      "  0.0643418 0.0864424 0.189929  0.156351  0.333852  0.536644  0.599855\n",
      "  0.275072  0.689577  0.19779   0.302872  0.639899  0.438495  0.642982\n",
      "  0.347101  0.770074  0.690163  0.611067  0.849532  0.563339  0.700984\n",
      "  0.820902  0.477018  0.638812  0.400313  0.410067  0.170831  0.487954\n",
      "  0.320365  0.45388   0.311799  0.534668  0.563793  0.727767  0.172686\n",
      "  0.908368  0.786892  0.790459  0.666388 ]\n",
      " [0.697707  0.432565  0.650329  0.886065  0.32866   0.576926  0.5231\n",
      "  0.0804626 0.131349  0.913496  0.785827  0.866454  0.212747  0.823783\n",
      "  0.847753  0.676257  0.832517  0.2925    0.610564  0.21335   0.712001\n",
      "  0.356027  0.216785  0.195093  0.295505  0.261591  0.869563  0.352044\n",
      "  0.657808  0.2174    0.561989  0.7218    0.383962  0.746319  0.703432\n",
      "  0.106694  0.187907  0.75822   0.201816  0.517488  0.417668  0.365065\n",
      "  0.665018  0.360463  0.308512  0.804057  0.356507  0.943264  0.087276\n",
      "  0.783484  0.290793  0.190144  0.470527  0.902304  0.564741  0.272694\n",
      "  0.357946  0.583892  0.444141  0.249423  0.11069   0.42077   0.250148\n",
      "  0.19635   0.427255  0.166715  0.91972  ]]\n",
      "\n",
      "First 5 rows in output.data:\n",
      "[0.733933 0.569419 0.832588 0.389664 0.725953]\n",
      "\n",
      "First 5 rows in pairs.data:\n",
      "[['\"D40\"' '\"T2\"']\n",
      " ['\"D31\"' '\"T64\"']\n",
      " ['\"D6\"' '\"T58\"']\n",
      " ['\"D56\"' '\"T49\"']\n",
      " ['\"D20\"' '\"T28\"']]\n"
     ]
    }
   ],
   "source": [
    "# Read the data files (input.data, output.data, pairs.data).\n",
    "\n",
    "input_features = np.loadtxt(\"input.data\")\n",
    "output_affinities = np.loadtxt(\"output.data\")\n",
    "pairs = np.genfromtxt(\"pairs.data\", dtype=str)  # Each row: [drug_id, protein_id]\n",
    "\n",
    "assert len(input_features) == len(output_affinities) == len(pairs), \"Error: the rows don't match\"\n",
    "\n",
    "print(\"First 5 rows in input.data:\")\n",
    "print(input_features[:5])\n",
    "print(\"\\nFirst 5 rows in output.data:\")\n",
    "print(output_affinities[:5])\n",
    "print(\"\\nFirst 5 rows in pairs.data:\")\n",
    "print(pairs[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement and run cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave-one-protein-out C-index: 0.830\n",
      "Leave-one-drug-out C-index: 0.520\n"
     ]
    }
   ],
   "source": [
    "# Implement and run the requested cross-validation. Report and interpret its results.\n",
    "\n",
    "#I wasn't sure if the input data should have been normalized because one row included many values.\n",
    "#scaler = StandardScaler()\n",
    "#input_features = scaler.fit_transform(input_features)\n",
    "\n",
    "protein_based_cindex = leave_one_group_out_cv(input_features, output_affinities, pairs, group_index=1)\n",
    "print(\"Leave-one-protein-out C-index: {:.3f}\".format(protein_based_cindex)) #if input_features are normalized C-index is 0.829\n",
    "\n",
    "drug_based_cindex = leave_one_group_out_cv(input_features, output_affinities, pairs, group_index=0)\n",
    "print(\"Leave-one-drug-out C-index: {:.3f}\".format(drug_based_cindex)) #if input_features are normalized C-index is 0.513"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The C-index (Concordance Index) is a measure of ranking quality, ranging from 0.5 (random chance) to 1.0 (perfect ranking). A higher C-index indicates that the model can correctly rank pairs by affinity.\n",
    "\n",
    "Leave-one-protein-out (C-index = 0.830)\n",
    "\n",
    "This is a reasonably high score, suggesting that the model generalizes well to new proteins.The model is still able to make relatively accurate affinity predictions when entirely new proteins are introduced.\n",
    "\n",
    "Leave-one-drug-out (C-index = 0.520)\n",
    "\n",
    "This is only slightly better than random (0.5), meaning the model struggles to predict affinities for entirely new drugs.\n",
    "This suggests that drug features may not be as informative as protein features, or that the model relies heavily on drug identity rather than true chemical properties. The model might be memorizing the drugs in the dataset rather than learning general principles about their interactions.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
